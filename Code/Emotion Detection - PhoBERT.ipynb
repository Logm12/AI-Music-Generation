{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":29550,"sourceType":"datasetVersion","datasetId":23079},{"sourceId":12201766,"sourceType":"datasetVersion","datasetId":7685997},{"sourceId":12219383,"sourceType":"datasetVersion","datasetId":7698359},{"sourceId":12253143,"sourceType":"datasetVersion","datasetId":7686189}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip\n\n!pip install transformers tokenizers\n\nprint(\"Successfully upgraded pip and installed transformers & tokenizers.\")","metadata":{"_uuid":"a334a3525c03f23a55668f55db390abca81eab20","_kg_hide-output":true,"_cell_guid":"a5f1f752-8365-40a8-a849-8ab2ab34db63","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:14:13.559200Z","iopub.execute_input":"2025-06-23T09:14:13.559486Z","iopub.status.idle":"2025-06-23T09:14:17.590137Z","shell.execute_reply.started":"2025-06-23T09:14:13.559465Z","shell.execute_reply":"2025-06-23T09:14:17.589032Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nSuccessfully upgraded pip and installed transformers & tokenizers.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:12:32.595704Z","iopub.execute_input":"2025-06-23T09:12:32.595991Z","iopub.status.idle":"2025-06-23T09:13:38.456430Z","shell.execute_reply.started":"2025-06-23T09:12:32.595962Z","shell.execute_reply":"2025-06-23T09:13:38.455668Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.417\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━\u001b[0m \u001b[32m0/7\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.10.19[nvidia-nvjitlink-cu12]\n\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.10.19:m \u001b[32m0/7\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.10.19━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.4.0.6━━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Uninstalling nvidia-cufft-cu12-11.4.0.6:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [nvidia-curand-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.9.0.13━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Uninstalling nvidia-cublas-cu12-12.9.0.13:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\u001b[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.9.5:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5━━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75━━━━━━━━━\u001b[0m \u001b[32m5/7\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m5/7\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.4.40[0m \u001b[32m5/7\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.4.40:90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m6/7\u001b[0m [nvidia-cusolver-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40━━━━━\u001b[0m \u001b[32m6/7\u001b[0m [nvidia-cusolver-cu12]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [nvidia-cusolver-cu12]dia-cusolver-cu12]\n\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport re\nimport random\nimport os\nimport unicodedata\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW                \nfrom transformers import get_scheduler, AutoTokenizer, AutoConfig, AutoModel \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nfrom datetime import timedelta\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:44:07.856447Z","iopub.execute_input":"2025-06-23T10:44:07.857009Z","iopub.status.idle":"2025-06-23T10:44:07.863674Z","shell.execute_reply.started":"2025-06-23T10:44:07.856985Z","shell.execute_reply":"2025-06-23T10:44:07.862826Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def set_seed(seed=42):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:16:18.548716Z","iopub.execute_input":"2025-06-23T09:16:18.549273Z","iopub.status.idle":"2025-06-23T09:16:18.556596Z","shell.execute_reply.started":"2025-06-23T09:16:18.549248Z","shell.execute_reply":"2025-06-23T09:16:18.556054Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mainnn/Data AI.csv\", sep=\";\", engine=\"python\", encoding=\"utf-8\")\nsentences = df['Sentence'].tolist()\nlabels = df['Emotion'].tolist()\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(sentences, encoded_labels, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:16:20.301673Z","iopub.execute_input":"2025-06-23T09:16:20.301980Z","iopub.status.idle":"2025-06-23T09:16:20.468504Z","shell.execute_reply.started":"2025-06-23T09:16:20.301957Z","shell.execute_reply":"2025-06-23T09:16:20.467889Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Tokenizer\nmodel_name = \"vinai/phobert-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\nconfig = AutoConfig.from_pretrained(model_name)\n\ntrain_encodings = tokenizer(train_texts, truncation=True, padding='max_length', max_length=128)\nval_encodings = tokenizer(val_texts, truncation=True, padding='max_length', max_length=128)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:16:22.815497Z","iopub.execute_input":"2025-06-23T09:16:22.816186Z","iopub.status.idle":"2025-06-23T09:16:33.208071Z","shell.execute_reply.started":"2025-06-23T09:16:22.816134Z","shell.execute_reply":"2025-06-23T09:16:33.207085Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8e3af28d1e4ec79d59cd2941454fcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5c3143e6ad848f3a88cd3a1038bd0b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5b5874dfc0a4ca3935a9746b4265f98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"119777ef855044cbae46a4e858f43fa9"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Dataset\nclass PhoBERTDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['label'] = torch.tensor(self.labels[idx])\n        return item\n\ntrain_dataset = PhoBERTDataset(train_encodings, train_labels)\nval_dataset = PhoBERTDataset(val_encodings, val_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:16:33.219365Z","iopub.execute_input":"2025-06-23T09:16:33.219610Z","iopub.status.idle":"2025-06-23T09:16:33.255944Z","shell.execute_reply.started":"2025-06-23T09:16:33.219589Z","shell.execute_reply":"2025-06-23T09:16:33.255111Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Model\nclass PhoBERTClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super().__init__()\n        self.phobert = AutoModel.from_pretrained(model_name, config=config)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.phobert.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.last_hidden_state[:, 0]\n        return self.classifier(self.dropout(pooled))\n\n# Init\nnum_classes = len(label_encoder.classes_)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = PhoBERTClassifier(num_classes).to(device)\noptimizer = AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\nscheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:16:33.257350Z","iopub.execute_input":"2025-06-23T09:16:33.257611Z","iopub.status.idle":"2025-06-23T09:16:53.541683Z","shell.execute_reply.started":"2025-06-23T09:16:33.257586Z","shell.execute_reply":"2025-06-23T09:16:53.540870Z"}},"outputs":[{"name":"stderr","text":"2025-06-23 09:16:39.035060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750670199.216353      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750670199.271760      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1374db61f024dffb035ee3be7e1d2cd"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Training & Evaluation\nhistory = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\nbest_acc = 0\nbest_model_state_dict = None\nbest_y_true, best_y_pred = [], []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:16:53.543322Z","iopub.execute_input":"2025-06-23T09:16:53.543941Z","iopub.status.idle":"2025-06-23T09:16:53.547816Z","shell.execute_reply.started":"2025-06-23T09:16:53.543922Z","shell.execute_reply":"2025-06-23T09:16:53.547020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"135e52746990429c8bed552335dc50f2"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    model.eval()\n    y_true, y_pred = [], []\n    total_loss = 0\n    with torch.no_grad():\n        for batch in dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids, attention_mask)\n            loss = loss_fn(outputs, labels)\n            preds = torch.argmax(outputs, dim=1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n            total_loss += loss.item()\n    acc = accuracy_score(y_true, y_pred)\n    return total_loss / len(dataloader), acc, y_true, y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:17:12.598422Z","iopub.execute_input":"2025-06-23T09:17:12.598971Z","iopub.status.idle":"2025-06-23T09:17:12.604066Z","shell.execute_reply.started":"2025-06-23T09:17:12.598949Z","shell.execute_reply":"2025-06-23T09:17:12.603395Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def format_time(elapsed):\n    elapsed_rounded = int(round((elapsed)))\n    return str(timedelta(seconds=elapsed_rounded))\n\ndef train_one_epoch(model, loader, optimizer, scheduler, loss_fn, device, epoch):\n    model.train()\n    total_loss = 0\n    pbar = tqdm(enumerate(loader), total=len(loader), desc=f\"Epoch {epoch:02d} | Training\")\n    for i, batch in pbar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n        current_lr = optimizer.param_groups[0]['lr']\n        avg_loss = total_loss / (i + 1)\n        pbar.set_postfix(avg_loss=f\"{avg_loss:.4f}\", lr=f\"{current_lr:.1e}\")\n    return total_loss / len(loader)\n\nprint(\"Starting training...\")\ntotal_t0 = time.time()\n\nhistory = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\nbest_acc = 0\nbest_model_state_dict = None\n\nfor epoch in range(1, 12):\n    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, loss_fn, device, epoch)\n    val_loss, val_acc, _, _ = evaluate(model, val_loader)\n    \n    print(f\"Epoch {epoch:02d} Summary | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n\n    history[\"train_loss\"].append(train_loss)\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_acc\"].append(val_acc)\n\n    if val_acc > best_acc:\n        best_acc = val_acc\n        best_model_state_dict = model.state_dict()\n        print(f\"----> Improved accuracy to {best_acc:.4f}. Best model updated. <----\")\n\ntotal_training_time = format_time(time.time() - total_t0)\nprint(\"\\n--- Training Complete ---\")\nprint(f\"Total training took: {total_training_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:17:24.821515Z","iopub.execute_input":"2025-06-23T09:17:24.821807Z","iopub.status.idle":"2025-06-23T10:25:01.367057Z","shell.execute_reply.started":"2025-06-23T09:17:24.821786Z","shell.execute_reply":"2025-06-23T10:25:01.366343Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 01 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24f2046094c548299ed54192bb6e091f"}},"metadata":{}},{"name":"stdout","text":"Epoch 01 Summary | Train Loss: 1.0081 | Val Loss: 0.6054 | Val Acc: 0.7992\n----> Improved accuracy to 0.7992. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 02 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"852a3f11130c4b689979abcfd46aa9a5"}},"metadata":{}},{"name":"stdout","text":"Epoch 02 Summary | Train Loss: 0.5389 | Val Loss: 0.5035 | Val Acc: 0.8341\n----> Improved accuracy to 0.8341. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 03 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab7a29a7752a416e9e596cd8816e741c"}},"metadata":{}},{"name":"stdout","text":"Epoch 03 Summary | Train Loss: 0.4078 | Val Loss: 0.4484 | Val Acc: 0.8547\n----> Improved accuracy to 0.8547. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 04 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"521fb0c437fc478a9704a7a1762aa156"}},"metadata":{}},{"name":"stdout","text":"Epoch 04 Summary | Train Loss: 0.3228 | Val Loss: 0.4480 | Val Acc: 0.8601\n----> Improved accuracy to 0.8601. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 05 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b286d7c6b6482ca0ad855543ccf160"}},"metadata":{}},{"name":"stdout","text":"Epoch 05 Summary | Train Loss: 0.2603 | Val Loss: 0.4341 | Val Acc: 0.8637\n----> Improved accuracy to 0.8637. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 06 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dc606df761b44c3965d14514e39ad0f"}},"metadata":{}},{"name":"stdout","text":"Epoch 06 Summary | Train Loss: 0.2139 | Val Loss: 0.4463 | Val Acc: 0.8652\n----> Improved accuracy to 0.8652. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 07 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38ea944aef3548ef9bf6fede2f178a71"}},"metadata":{}},{"name":"stdout","text":"Epoch 07 Summary | Train Loss: 0.1803 | Val Loss: 0.4672 | Val Acc: 0.8649\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 08 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"021e64ae7b654c7aa18d5ef0a9c3c806"}},"metadata":{}},{"name":"stdout","text":"Epoch 08 Summary | Train Loss: 0.1570 | Val Loss: 0.4668 | Val Acc: 0.8658\n----> Improved accuracy to 0.8658. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 09 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff3062664c6a40d9b93bb6fb8e27d146"}},"metadata":{}},{"name":"stdout","text":"Epoch 09 Summary | Train Loss: 0.1408 | Val Loss: 0.4561 | Val Acc: 0.8702\n----> Improved accuracy to 0.8702. Best model updated. <----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e96a917fff3644fbbfbd7a8a4875584f"}},"metadata":{}},{"name":"stdout","text":"Epoch 10 Summary | Train Loss: 0.1302 | Val Loss: 0.4592 | Val Acc: 0.8693\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11 | Training:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8736f032cc9a4491baac6e88bd29c7b6"}},"metadata":{}},{"name":"stdout","text":"Epoch 11 Summary | Train Loss: 0.1235 | Val Loss: 0.4592 | Val Acc: 0.8693\n\n--- Training Complete ---\nTotal training took: 1:07:37\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(f\" Best Validation Accuracy: {best_acc:.4f}\")\nbest_model_path = \"/kaggle/working/phobert_best_model1.pt\"\ntorch.save(best_model_state_dict, best_model_path)\nprint(f\"Best model saved to: {best_model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:26:15.183769Z","iopub.execute_input":"2025-06-23T10:26:15.184432Z","iopub.status.idle":"2025-06-23T10:26:16.050572Z","shell.execute_reply.started":"2025-06-23T10:26:15.184405Z","shell.execute_reply":"2025-06-23T10:26:16.049729Z"}},"outputs":[{"name":"stdout","text":" Best Validation Accuracy: 0.8702\nBest model saved to: /kaggle/working/phobert_best_model1.pt\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def get_predictions_and_probabilities(model, dataloader, device):\n    model.eval()\n    y_true, y_pred, y_proba = [], [], []\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids, attention_mask)\n            preds = torch.argmax(outputs, dim=1)\n            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n            y_proba.extend(probabilities.cpu().numpy())\n    return np.array(y_true), np.array(y_pred), np.array(y_proba)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:44:31.054748Z","iopub.execute_input":"2025-06-23T10:44:31.055033Z","iopub.status.idle":"2025-06-23T10:44:31.060856Z","shell.execute_reply.started":"2025-06-23T10:44:31.055011Z","shell.execute_reply":"2025-06-23T10:44:31.060020Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# The comprehensive display function (Corrected for the warning)\ndef display_all_results(y_true, y_pred, y_proba, class_labels, history):\n    print(\"              CLASSIFICATION REPORT ON TEST SET\")\n    print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n\n    fig = plt.figure(figsize=(24, 30))\n    gs = fig.add_gridspec(4, 2)\n\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax1.plot(history['train_loss'], 'b-o', label='Train Loss')\n    ax1.plot(history['val_loss'], 'r-o', label='Val Loss')\n    ax1.set_title('Loss over Epochs', fontsize=16)\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.legend()\n\n    ax2 = fig.add_subplot(gs[0, 1])\n    ax2.plot(history['val_acc'], 'g-o', label='Val Accuracy')\n    ax2.set_title('Validation Accuracy over Epochs', fontsize=16)\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.legend()\n    \n    ax3 = fig.add_subplot(gs[1, :])\n    report_dict = classification_report(y_true, y_pred, target_names=class_labels, output_dict=True)\n    report_df = pd.DataFrame(report_dict).iloc[:-1, :].T\n    sns.heatmap(report_df, annot=True, cmap='viridis', fmt='.4f', ax=ax3, annot_kws={\"size\": 12})\n    ax3.set_title('Classification Report Heatmap', fontsize=16)\n    \n    ax4 = fig.add_subplot(gs[2, 0])\n    cm = confusion_matrix(y_true, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n    disp.plot(cmap='Blues', ax=ax4, xticks_rotation=45)\n    ax4.set_title('Confusion Matrix', fontsize=16)\n\n    ax5 = fig.add_subplot(gs[2, 1])\n    report_df_metrics = report_df[['precision', 'recall', 'f1-score']].drop(['accuracy', 'macro avg', 'weighted avg'])\n    report_df_metrics.plot(kind='barh', ax=ax5)\n    ax5.set_title('Per-Class Performance Metrics', fontsize=16)\n    ax5.set_xlabel('Score')\n    ax5.grid(axis='x', linestyle='--')\n    \n    ax6 = fig.add_subplot(gs[3, :])\n    y_true_bin = label_binarize(y_true, classes=range(len(class_labels)))\n\n    cmap = plt.colormaps['tab10'] \n    colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n    \n    for i, class_name in enumerate(class_labels):\n        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_proba[:, i])\n        roc_auc = auc(fpr, tpr)\n        ax6.plot(fpr, tpr, color=colors[i], lw=2, label=f'{class_name} (AUC = {roc_auc:.4f})')\n        \n    ax6.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n    ax6.set_xlim([0.0, 1.0])\n    ax6.set_ylim([0.0, 1.05])\n    ax6.set_xlabel('False Positive Rate', fontsize=12)\n    ax6.set_ylabel('True Positive Rate', fontsize=12)\n    ax6.set_title('Receiver Operating Characteristic (ROC) Curves', fontsize=16)\n    ax6.legend(loc=\"lower right\")\n    ax6.grid(True)\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:44:33.353965Z","iopub.execute_input":"2025-06-23T10:44:33.354684Z","iopub.status.idle":"2025-06-23T10:44:33.366296Z","shell.execute_reply.started":"2025-06-23T10:44:33.354660Z","shell.execute_reply":"2025-06-23T10:44:33.365593Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"\nprint(\"Loading best model for final evaluation...\")\nmodel.load_state_dict(best_model_state_dict)\n\ny_true_final, y_pred_final, y_proba_final = get_predictions_and_probabilities(\n    model, \n    val_loader,\n    device\n)\n\n# 4. Define your class labels from the encoder\nclass_names = list(label_encoder.classes_)\n\n# 5. Display everything!\ndisplay_all_results(y_true_final, y_pred_final, y_proba_final, class_names, history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:44:36.679107Z","iopub.execute_input":"2025-06-23T10:44:36.679424Z"}},"outputs":[{"name":"stdout","text":"Loading best model for final evaluation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/59 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c0d5531626467abde3c9ab32fecc6d"}},"metadata":{}},{"name":"stdout","text":"              CLASSIFICATION REPORT ON TEST SET\n              precision    recall  f1-score   support\n\n     buồn bã     0.8600    0.8970    0.8781      1233\n     ghê tởm     0.8654    0.8730    0.8692      1134\n  ngạc nhiên     0.8361    0.8280    0.8320      1041\n      sợ hãi     0.8700    0.8744    0.8722      1194\n    tức giận     0.8903    0.8932    0.8917      1535\n      vui vẻ     0.8826    0.8418    0.8617      1384\n\n    accuracy                         0.8693      7521\n   macro avg     0.8674    0.8679    0.8675      7521\nweighted avg     0.8694    0.8693    0.8692      7521\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def predict_with_confidence(text, model, tokenizer, label_encoder, device):\n    # Set the model to evaluation mode\n    model.eval()\n    \n    encoded_text = tokenizer(\n        text,\n        truncation=True,\n        padding='max_length',\n        max_length=128,\n        return_tensors='pt' \n    )\n    \n    input_ids = encoded_text['input_ids'].to(device)\n    attention_mask = encoded_text['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask)\n        \n        probabilities = F.softmax(outputs, dim=1)\n        \n        confidence, predicted_idx = torch.max(probabilities, dim=1)\n        \n        predicted_label = label_encoder.inverse_transform(predicted_idx.cpu().numpy())[0]\n        \n        all_probs = probabilities.cpu().numpy().flatten()\n        class_labels = label_encoder.classes_\n        confidence_per_label = {label: prob for label, prob in zip(class_labels, all_probs)}\n        \n    return predicted_label, confidence.item(), confidence_per_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:45:10.407796Z","iopub.execute_input":"2025-06-23T10:45:10.408426Z","iopub.status.idle":"2025-06-23T10:45:10.413932Z","shell.execute_reply.started":"2025-06-23T10:45:10.408401Z","shell.execute_reply":"2025-06-23T10:45:10.413234Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"\nprint(\"Loading best model for prediction...\")\nmodel.load_state_dict(best_model_state_dict)\nmodel.to(device)\n\ninput_text = \"trời ơi sản phẩm này tốt ngoài sức tưởng tượng của mình\"\n\npredicted_label, confidence, all_confidences = predict_with_confidence(\n    input_text, \n    model, \n    tokenizer, \n    label_encoder, \n    device\n)\n\nprint(f\"\\nInput Text: '{input_text}'\")\nprint(\"-\" * 50)\nprint(f\"==> Final Prediction: {predicted_label.upper()} (Confidence: {confidence:.2%})\")\nprint(\"-\" * 50)\nprint(\"Confidence Breakdown:\")\nsorted_confidences = sorted(all_confidences.items(), key=lambda item: item[1], reverse=True)\nfor label, prob in sorted_confidences:\n    print(f\"- {label:<12}: {prob:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:45:13.262763Z","iopub.execute_input":"2025-06-23T10:45:13.263265Z","iopub.status.idle":"2025-06-23T10:45:13.291598Z","shell.execute_reply.started":"2025-06-23T10:45:13.263231Z","shell.execute_reply":"2025-06-23T10:45:13.290929Z"}},"outputs":[{"name":"stdout","text":"Loading best model for prediction...\n\nInput Text: 'trời ơi sản phẩm này tốt ngoài sức tưởng tượng của mình'\n--------------------------------------------------\n==> Final Prediction: VUI VẺ (Confidence: 60.06%)\n--------------------------------------------------\nConfidence Breakdown:\n- vui vẻ      : 60.06%\n- ngạc nhiên  : 23.34%\n- buồn bã     : 15.71%\n- sợ hãi      : 0.48%\n- tức giận    : 0.23%\n- ghê tởm     : 0.18%\n","output_type":"stream"}],"execution_count":44}]}